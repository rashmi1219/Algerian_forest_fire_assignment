{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b05a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0cf5eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Bejaia Region Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <td>Classes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <th>06</th>\n",
       "      <th>2012</th>\n",
       "      <th>29</th>\n",
       "      <th>57</th>\n",
       "      <th>18</th>\n",
       "      <th>0</th>\n",
       "      <th>65.7</th>\n",
       "      <th>3.4</th>\n",
       "      <th>7.6</th>\n",
       "      <th>1.3</th>\n",
       "      <th>3.4</th>\n",
       "      <th>0.5</th>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <th>06</th>\n",
       "      <th>2012</th>\n",
       "      <th>29</th>\n",
       "      <th>61</th>\n",
       "      <th>13</th>\n",
       "      <th>1.3</th>\n",
       "      <th>64.4</th>\n",
       "      <th>4.1</th>\n",
       "      <th>7.6</th>\n",
       "      <th>1</th>\n",
       "      <th>3.9</th>\n",
       "      <th>0.4</th>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <th>06</th>\n",
       "      <th>2012</th>\n",
       "      <th>26</th>\n",
       "      <th>82</th>\n",
       "      <th>22</th>\n",
       "      <th>13.1</th>\n",
       "      <th>47.1</th>\n",
       "      <th>2.5</th>\n",
       "      <th>7.1</th>\n",
       "      <th>0.3</th>\n",
       "      <th>2.7</th>\n",
       "      <th>0.1</th>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <th>06</th>\n",
       "      <th>2012</th>\n",
       "      <th>25</th>\n",
       "      <th>89</th>\n",
       "      <th>13</th>\n",
       "      <th>2.5</th>\n",
       "      <th>28.6</th>\n",
       "      <th>1.3</th>\n",
       "      <th>6.9</th>\n",
       "      <th>0</th>\n",
       "      <th>1.7</th>\n",
       "      <th>0</th>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <th>09</th>\n",
       "      <th>2012</th>\n",
       "      <th>30</th>\n",
       "      <th>65</th>\n",
       "      <th>14</th>\n",
       "      <th>0</th>\n",
       "      <th>85.4</th>\n",
       "      <th>16</th>\n",
       "      <th>44.5</th>\n",
       "      <th>4.5</th>\n",
       "      <th>16.9</th>\n",
       "      <th>6.5</th>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>09</th>\n",
       "      <th>2012</th>\n",
       "      <th>28</th>\n",
       "      <th>87</th>\n",
       "      <th>15</th>\n",
       "      <th>4.4</th>\n",
       "      <th>41.1</th>\n",
       "      <th>6.5</th>\n",
       "      <th>8</th>\n",
       "      <th>0.1</th>\n",
       "      <th>6.2</th>\n",
       "      <th>0</th>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <th>09</th>\n",
       "      <th>2012</th>\n",
       "      <th>27</th>\n",
       "      <th>87</th>\n",
       "      <th>29</th>\n",
       "      <th>0.5</th>\n",
       "      <th>45.9</th>\n",
       "      <th>3.5</th>\n",
       "      <th>7.9</th>\n",
       "      <th>0.4</th>\n",
       "      <th>3.4</th>\n",
       "      <th>0.2</th>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <th>09</th>\n",
       "      <th>2012</th>\n",
       "      <th>24</th>\n",
       "      <th>54</th>\n",
       "      <th>18</th>\n",
       "      <th>0.1</th>\n",
       "      <th>79.7</th>\n",
       "      <th>4.3</th>\n",
       "      <th>15.2</th>\n",
       "      <th>1.7</th>\n",
       "      <th>5.1</th>\n",
       "      <th>0.7</th>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>09</th>\n",
       "      <th>2012</th>\n",
       "      <th>24</th>\n",
       "      <th>64</th>\n",
       "      <th>15</th>\n",
       "      <th>0.2</th>\n",
       "      <th>67.3</th>\n",
       "      <th>3.8</th>\n",
       "      <th>16.5</th>\n",
       "      <th>1.2</th>\n",
       "      <th>4.8</th>\n",
       "      <th>0.5</th>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    Bejaia Region Dataset \n",
       "day month year Temperature  RH  Ws Rain  FFMC DMC DC   ISI BUI  FWI              Classes  \n",
       "01  06    2012 29          57  18  0     65.7 3.4 7.6  1.3 3.4  0.5            not fire   \n",
       "02  06    2012 29          61  13  1.3   64.4 4.1 7.6  1   3.9  0.4            not fire   \n",
       "03  06    2012 26          82  22  13.1  47.1 2.5 7.1  0.3 2.7  0.1            not fire   \n",
       "04  06    2012 25          89  13  2.5   28.6 1.3 6.9  0   1.7  0              not fire   \n",
       "...                                                                                    ...\n",
       "26  09    2012 30          65  14  0     85.4 16  44.5 4.5 16.9 6.5                fire   \n",
       "27  09    2012 28          87  15  4.4   41.1 6.5 8    0.1 6.2  0              not fire   \n",
       "28  09    2012 27          87  29  0.5   45.9 3.5 7.9  0.4 3.4  0.2            not fire   \n",
       "29  09    2012 24          54  18  0.1   79.7 4.3 15.2 1.7 5.1  0.7            not fire   \n",
       "30  09    2012 24          64  15  0.2   67.3 3.8 16.5 1.2 4.8  0.5           not fire    \n",
       "\n",
       "[247 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"Algerian_forest_fires_dataset_UPDATE (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8da05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Algerian_forest_fires_dataset_UPDATE (1).csv\",skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdeafc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>26</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>85.4</td>\n",
       "      <td>16</td>\n",
       "      <td>44.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>27</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>4.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>28</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>29</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>30</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    day month  year Temperature  RH  Ws Rain   FFMC  DMC    DC  ISI   BUI  \\\n",
       "0    01    06  2012          29  57  18     0  65.7  3.4   7.6  1.3   3.4   \n",
       "1    02    06  2012          29  61  13   1.3  64.4  4.1   7.6    1   3.9   \n",
       "2    03    06  2012          26  82  22  13.1  47.1  2.5   7.1  0.3   2.7   \n",
       "3    04    06  2012          25  89  13   2.5  28.6  1.3   6.9    0   1.7   \n",
       "4    05    06  2012          27  77  16     0  64.8    3  14.2  1.2   3.9   \n",
       "..   ..   ...   ...         ...  ..  ..   ...   ...  ...   ...  ...   ...   \n",
       "241  26    09  2012          30  65  14     0  85.4   16  44.5  4.5  16.9   \n",
       "242  27    09  2012          28  87  15   4.4  41.1  6.5     8  0.1   6.2   \n",
       "243  28    09  2012          27  87  29   0.5  45.9  3.5   7.9  0.4   3.4   \n",
       "244  29    09  2012          24  54  18   0.1  79.7  4.3  15.2  1.7   5.1   \n",
       "245  30    09  2012          24  64  15   0.2  67.3  3.8  16.5  1.2   4.8   \n",
       "\n",
       "     FWI     Classes    \n",
       "0    0.5   not fire     \n",
       "1    0.4   not fire     \n",
       "2    0.1   not fire     \n",
       "3      0   not fire     \n",
       "4    0.5   not fire     \n",
       "..   ...           ...  \n",
       "241  6.5       fire     \n",
       "242    0   not fire     \n",
       "243  0.2   not fire     \n",
       "244  0.7   not fire     \n",
       "245  0.5  not fire      \n",
       "\n",
       "[246 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10e1adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first consider this as a classification problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "587cb0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>246</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>174</td>\n",
       "      <td>167</td>\n",
       "      <td>199</td>\n",
       "      <td>107</td>\n",
       "      <td>175</td>\n",
       "      <td>128</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>01</td>\n",
       "      <td>07</td>\n",
       "      <td>2012</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>244</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        day month  year Temperature   RH   Ws Rain   FFMC  DMC   DC  ISI  BUI  \\\n",
       "count   246   245   245         245  245  245   245   245  245  245  245  245   \n",
       "unique   33     5     2          20   63   19    40   174  167  199  107  175   \n",
       "top      01    07  2012          35   64   14     0  88.9  7.9    8  1.1    3   \n",
       "freq      8    62   244          29   10   43   133     8    5    5    8    5   \n",
       "\n",
       "        FWI Classes    \n",
       "count   245       244  \n",
       "unique  128         9  \n",
       "top     0.4   fire     \n",
       "freq     12       131  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3fd4062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['06', '07', '08', '09', nan, 'month'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['month'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b076ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2012', nan, 'year'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd17fa45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '30', '31',\n",
       "       'Sidi-Bel Abbes Region Dataset', 'day'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d03a004f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '30', '31',\n",
       "       'Sidi-Bel Abbes Region Dataset', 'day'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "970ba5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'month', 'year', 'Temperature', ' RH', ' Ws', 'Rain ', 'FFMC',\n",
       "       'DMC', 'DC', 'ISI', 'BUI', 'FWI', 'Classes  '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b91a9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['classes'] = data['Classes  '] #here there is space in column name so we have copied the data of this column to classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e93d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Classes  ', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "344670dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05</td>\n",
       "      <td>06</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>26</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>85.4</td>\n",
       "      <td>16</td>\n",
       "      <td>44.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>27</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>4.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>28</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>29</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>30</td>\n",
       "      <td>09</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>not fire</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    day month  year Temperature  RH  Ws Rain   FFMC  DMC    DC  ISI   BUI  \\\n",
       "0    01    06  2012          29  57  18     0  65.7  3.4   7.6  1.3   3.4   \n",
       "1    02    06  2012          29  61  13   1.3  64.4  4.1   7.6    1   3.9   \n",
       "2    03    06  2012          26  82  22  13.1  47.1  2.5   7.1  0.3   2.7   \n",
       "3    04    06  2012          25  89  13   2.5  28.6  1.3   6.9    0   1.7   \n",
       "4    05    06  2012          27  77  16     0  64.8    3  14.2  1.2   3.9   \n",
       "..   ..   ...   ...         ...  ..  ..   ...   ...  ...   ...  ...   ...   \n",
       "241  26    09  2012          30  65  14     0  85.4   16  44.5  4.5  16.9   \n",
       "242  27    09  2012          28  87  15   4.4  41.1  6.5     8  0.1   6.2   \n",
       "243  28    09  2012          27  87  29   0.5  45.9  3.5   7.9  0.4   3.4   \n",
       "244  29    09  2012          24  54  18   0.1  79.7  4.3  15.2  1.7   5.1   \n",
       "245  30    09  2012          24  64  15   0.2  67.3  3.8  16.5  1.2   4.8   \n",
       "\n",
       "     FWI       classes  \n",
       "0    0.5   not fire     \n",
       "1    0.4   not fire     \n",
       "2    0.1   not fire     \n",
       "3      0   not fire     \n",
       "4    0.5   not fire     \n",
       "..   ...           ...  \n",
       "241  6.5       fire     \n",
       "242    0   not fire     \n",
       "243  0.2   not fire     \n",
       "244  0.7   not fire     \n",
       "245  0.5  not fire      \n",
       "\n",
       "[246 rows x 14 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8531289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not fire   ', 'fire   ', 'fire', 'fire ', 'not fire', 'not fire ',\n",
       "       nan, 'Classes  ', 'not fire     ', 'not fire    '], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['classes'].unique() # here in actual there are only two classes but because of space in string it has become 9 classes\n",
    "# here we will replace the nan and 'classes' with fire as it is the mode value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1037f6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['classes'] = data['classes'].map({'not fire   ':0, 'fire   ':1,'fire':1,'fire ':1, 'not fire':0, 'not fire ':0,'Classes  ':1,'not fire     ':0,'not fire    ':0  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "047dde17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['classes'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f94196f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['classes'].fillna(data['classes'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6064f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['classes'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99ada8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['classes'] = data['classes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbd5b0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['classes'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b332b0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246 entries, 0 to 245\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   day          246 non-null    object\n",
      " 1   month        245 non-null    object\n",
      " 2   year         245 non-null    object\n",
      " 3   Temperature  245 non-null    object\n",
      " 4    RH          245 non-null    object\n",
      " 5    Ws          245 non-null    object\n",
      " 6   Rain         245 non-null    object\n",
      " 7   FFMC         245 non-null    object\n",
      " 8   DMC          245 non-null    object\n",
      " 9   DC           245 non-null    object\n",
      " 10  ISI          245 non-null    object\n",
      " 11  BUI          245 non-null    object\n",
      " 12  FWI          245 non-null    object\n",
      " 13  classes      246 non-null    int32 \n",
      "dtypes: int32(1), object(13)\n",
      "memory usage: 26.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc40fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#above it is showing all the data as object data type, out of it we have to convert some feature as numerical data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f6d1573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '30', '31',\n",
       "       'Sidi-Bel Abbes Region Dataset', 'day'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a16a988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Sidi-Bel Abbes Region Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               day month year Temperature   RH   Ws Rain   \\\n",
       "122  Sidi-Bel Abbes Region Dataset   NaN  NaN         NaN  NaN  NaN   NaN   \n",
       "\n",
       "    FFMC  DMC   DC  ISI  BUI  FWI  classes  \n",
       "122  NaN  NaN  NaN  NaN  NaN  NaN        1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['day'] == 'Sidi-Bel Abbes Region Dataset' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22092cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as all the value in row 122 is nan we will delete this row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a57c2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(labels=122, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ae910ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0102361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as row number 122 is deleted row number is dcreased from 246 to 245"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0222bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11',\n",
       "       '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '30', '31', 'day'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1594421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     245\n",
       "unique     32\n",
       "top        01\n",
       "freq        8\n",
       "Name: day, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c538e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "754accf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[df['day'] == 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cac88411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['day'].replace('day','01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d84185ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    245.000000\n",
       "mean      15.693878\n",
       "std        8.857256\n",
       "min        1.000000\n",
       "25%        8.000000\n",
       "50%       16.000000\n",
       "75%       23.000000\n",
       "max       31.000000\n",
       "Name: day, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['day'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5558ea44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c1a0f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'] = df['day'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eb0c870a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 245 entries, 0 to 245\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   day          245 non-null    int32 \n",
      " 1   month        245 non-null    int32 \n",
      " 2   year         245 non-null    object\n",
      " 3   Temperature  245 non-null    object\n",
      " 4    RH          245 non-null    object\n",
      " 5    Ws          245 non-null    object\n",
      " 6   Rain         245 non-null    object\n",
      " 7   FFMC         245 non-null    object\n",
      " 8   DMC          245 non-null    object\n",
      " 9   DC           245 non-null    object\n",
      " 10  ISI          245 non-null    object\n",
      " 11  BUI          245 non-null    object\n",
      " 12  FWI          245 non-null    object\n",
      " 13  classes      245 non-null    int32 \n",
      "dtypes: int32(3), object(11)\n",
      "memory usage: 33.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5fc1ec9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 8, 9])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5025fedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [day, month, year, Temperature,  RH,  Ws, Rain , FFMC, DMC, DC, ISI, BUI, FWI, classes]\n",
       "Index: []"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['month'] == 'month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7a341b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>174</td>\n",
       "      <td>167</td>\n",
       "      <td>199</td>\n",
       "      <td>107</td>\n",
       "      <td>175</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2012</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>244</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>133</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year Temperature   RH   Ws Rain   FFMC  DMC   DC  ISI  BUI  FWI\n",
       "count    245         245  245  245   245   245  245  245  245  245  245\n",
       "unique     2          20   63   19    40   174  167  199  107  175  128\n",
       "top     2012          35   64   14     0  88.9  7.9    8  1.1    3  0.4\n",
       "freq     244          29   10   43   133     8    5    5    8    5   12"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "65e7cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['month'].replace('month', '07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "50d17d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 8, 9])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "faab1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8b4bdbe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 8, 9])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "50e33425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 245 entries, 0 to 245\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   day          245 non-null    int32 \n",
      " 1   month        245 non-null    int32 \n",
      " 2   year         245 non-null    object\n",
      " 3   Temperature  245 non-null    object\n",
      " 4    RH          245 non-null    object\n",
      " 5    Ws          245 non-null    object\n",
      " 6   Rain         245 non-null    object\n",
      " 7   FFMC         245 non-null    object\n",
      " 8   DMC          245 non-null    object\n",
      " 9   DC           245 non-null    object\n",
      " 10  ISI          245 non-null    object\n",
      " 11  BUI          245 non-null    object\n",
      " 12  FWI          245 non-null    object\n",
      " 13  classes      245 non-null    int32 \n",
      "dtypes: int32(3), object(11)\n",
      "memory usage: 33.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "556e95f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2012', 'year'], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc3e145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>year</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>RH</td>\n",
       "      <td>Ws</td>\n",
       "      <td>Rain</td>\n",
       "      <td>FFMC</td>\n",
       "      <td>DMC</td>\n",
       "      <td>DC</td>\n",
       "      <td>ISI</td>\n",
       "      <td>BUI</td>\n",
       "      <td>FWI</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month  year  Temperature   RH   Ws  Rain   FFMC  DMC  DC  ISI  BUI  \\\n",
       "123    1      7  year  Temperature   RH   Ws  Rain   FFMC  DMC  DC  ISI  BUI   \n",
       "\n",
       "     FWI  classes  \n",
       "123  FWI        1  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['year'] == 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ae057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here in row 123 as all the value is same as column name we can drop this row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c4a623eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(labels = 123, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0ede00d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "day            0\n",
       "month          0\n",
       "year           0\n",
       "Temperature    0\n",
       " RH            0\n",
       " Ws            0\n",
       "Rain           0\n",
       "FFMC           0\n",
       "DMC            0\n",
       "DC             0\n",
       "ISI            0\n",
       "BUI            0\n",
       "FWI            0\n",
       "classes        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4b7a391a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 244 entries, 0 to 245\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   day          244 non-null    int32 \n",
      " 1   month        244 non-null    int32 \n",
      " 2   year         244 non-null    object\n",
      " 3   Temperature  244 non-null    object\n",
      " 4    RH          244 non-null    object\n",
      " 5    Ws          244 non-null    object\n",
      " 6   Rain         244 non-null    object\n",
      " 7   FFMC         244 non-null    object\n",
      " 8   DMC          244 non-null    object\n",
      " 9   DC           244 non-null    object\n",
      " 10  ISI          244 non-null    object\n",
      " 11  BUI          244 non-null    object\n",
      " 12  FWI          244 non-null    object\n",
      " 13  classes      244 non-null    int32 \n",
      "dtypes: int32(3), object(11)\n",
      "memory usage: 25.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ddf42dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  month  year Temperature  RH  Ws Rain   FFMC  DMC    DC  ISI  BUI  FWI  \\\n",
       "0    1      6  2012          29  57  18     0  65.7  3.4   7.6  1.3  3.4  0.5   \n",
       "1    2      6  2012          29  61  13   1.3  64.4  4.1   7.6    1  3.9  0.4   \n",
       "2    3      6  2012          26  82  22  13.1  47.1  2.5   7.1  0.3  2.7  0.1   \n",
       "3    4      6  2012          25  89  13   2.5  28.6  1.3   6.9    0  1.7    0   \n",
       "4    5      6  2012          27  77  16     0  64.8    3  14.2  1.2  3.9  0.5   \n",
       "\n",
       "   classes  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "05e6aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as there is only one value for year we can drop this column as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cbb5ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='year', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "de7a8be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month Temperature  RH  Ws Rain   FFMC  DMC    DC  ISI  BUI  FWI  \\\n",
       "245   30      9          24  64  15   0.2  67.3  3.8  16.5  1.2  4.8  0.5   \n",
       "\n",
       "     classes  \n",
       "245        0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "68cdd32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Temperature'] = df['Temperature'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3de3b1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'month', 'Temperature', ' RH', ' Ws', 'Rain ', 'FFMC', 'DMC',\n",
       "       'DC', 'ISI', 'BUI', 'FWI', 'classes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f5dd91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' RH'] = df[' RH'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8bb34efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'month', 'Temperature', ' RH', ' Ws', 'Rain ', 'FFMC', 'DMC',\n",
       "       'DC', 'ISI', 'BUI', 'FWI', 'classes', 'RH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e7f42d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['18', '13', '22', '16', '14', '15', '12', '19', '21', '20', '17',\n",
       "       '26', '11', '10', '9', '8', '6', '29'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' Ws'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a7c3f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[' Ws'] = df[' Ws'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "619bdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rain ' ] = df['Rain '].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0aa7fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FFMC'] = df['FFMC'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f8708ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DMC'] = df['DMC'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "442cb0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['7.6', '7.1', '6.9', '14.2', '22.2', '30.5', '38.3', '38.8',\n",
       "       '46.3', '54.3', '61.4', '17', '7.8', '7.4', '8', '16', '27.1',\n",
       "       '31.6', '39.5', '47.7', '55.8', '63.8', '71.8', '80.3', '88.5',\n",
       "       '84.4', '92.8', '8.6', '8.3', '9.2', '18.5', '27.9', '37', '40.4',\n",
       "       '49.8', '9.3', '18.7', '27.7', '37.2', '22.9', '25.5', '34.1',\n",
       "       '43.1', '52.8', '62.1', '71.5', '79.9', '71.3', '79.7', '88.7',\n",
       "       '98.6', '108.5', '117.8', '127', '136', '145.7', '10.2', '10',\n",
       "       '19.8', '29.7', '39.1', '48.6', '47', '57', '67', '77', '75.1',\n",
       "       '85.1', '94.7', '92.5', '90.4', '100.7', '110.9', '120.9', '130.6',\n",
       "       '141.1', '151.3', '161.5', '171.3', '181.3', '190.6', '200.2',\n",
       "       '210.4', '220.4', '180.4', '8.7', '7.5', '7', '15.7', '24', '32.2',\n",
       "       '30.1', '8.4', '8.9', '16.6', '7.3', '24.3', '33.1', '41.3',\n",
       "       '49.3', '57.9', '41.4', '30.4', '15.2', '7.7', '16.3', '24.9',\n",
       "       '8.8', '8.2', '15.4', '17.6', '26.3', '28.9', '14.7', '22.5',\n",
       "       '37.8', '18.4', '25.6', '34.5', '43.3', '52.4', '36.7', '8.5',\n",
       "       '17.8', '27.3', '36.8', '46.4', '45.1', '35.4', '9.7', '9.9',\n",
       "       '9.5', '19.4', '10.4', '14.6 9', '24.1', '42.3', '51.6', '61.1',\n",
       "       '71', '80.6', '90.1', '99', '56.6', '15.9', '19.7', '28.3', '37.6',\n",
       "       '47.2', '57.1', '67.2', '10.5', '21.4', '32.1', '42.7', '52.5',\n",
       "       '9.1', '9.8', '20.2', '30.9', '41.5', '55.5', '54.2', '65.1',\n",
       "       '76.4', '86.8', '96.8', '107', '117.1', '127.5', '137.7', '147.7',\n",
       "       '157.5', '167.2', '177.3', '166', '149.2', '159.1', '168.2',\n",
       "       '26.6', '17.7', '26.1', '25.2', '33.4', '50.2', '59.2', '63.3',\n",
       "       '77.8', '86', '88', '97.3', '106.3', '115.6', '28.1', '36.1',\n",
       "       '44.5', '7.9', '16.5'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "edaa895f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '14.6 9'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17992/1964755474.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DC'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DC'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5813\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5814\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5815\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5816\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m         \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[1;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m   1199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[1;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '14.6 9'"
     ]
    }
   ],
   "source": [
    "df['DC'] = df['DC'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3dc5c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DC'] = df['DC'].replace('14.6 9', '14.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "86f03414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DC'] = df['DC'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0acdc2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ISI'] = df['ISI'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5fa96e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BUI'] = df['BUI'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4d23b43",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'fire   '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17992/1842677952.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FWI'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FWI'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5813\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5814\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5815\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5816\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1308\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1309\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1310\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m         \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[1;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m   1199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[1;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'fire   '"
     ]
    }
   ],
   "source": [
    "df['FWI'] = df['FWI'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d151c592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0.5', '0.4', '0.1', '0', '2.5', '7.2', '7.1', '0.3', '0.9', '5.6',\n",
       "       '7.1 ', '0.2', '1.4', '2.2', '2.3', '3.8', '7.5', '8.4', '10.6',\n",
       "       '15', '13.9', '3.9', '12.9', '1.7', '4.9', '6.8', '3.2', '8',\n",
       "       '0.6', '3.4', '0.8', '3.6', '6', '10.9', '4', '8.8', '2.8', '2.1',\n",
       "       '1.3', '7.3', '15.3', '11.3', '11.9', '10.7', '15.7', '6.1', '2.6',\n",
       "       '9.9', '11.6', '12.1', '4.2', '10.2', '6.3', '14.6', '16.1',\n",
       "       '17.2', '16.8', '18.4', '20.4', '22.3', '20.9', '20.3', '13.7',\n",
       "       '13.2', '19.9', '30.2', '5.9', '7.7', '9.7', '8.3', '0.7', '4.1',\n",
       "       '1', '3.1', '1.9', '10', '16.7', '1.2', '5.3', '6.7', '9.5', '12',\n",
       "       '6.4', '5.2', '3', '9.6', '4.7', 'fire   ', '14.1', '9.1', '13',\n",
       "       '17.3', '30', '25.4', '16.3', '9', '14.5', '13.5', '19.5', '12.6',\n",
       "       '12.7', '21.6', '18.8', '10.5', '5.5', '14.8', '24', '26.3',\n",
       "       '12.2', '18.1', '24.5', '26.9', '31.1', '30.3', '26.1', '16',\n",
       "       '19.4', '2.7', '3.7', '10.3', '5.7', '9.8', '19.3', '17.5', '15.4',\n",
       "       '15.2', '6.5'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FWI'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "edcf90d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>88.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.4</td>\n",
       "      <td>fire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month  Temperature   RH    Ws  Rain   FFMC   DMC    DC   ISI   BUI  \\\n",
       "167   14      7           37   37  18.0    0.2  88.9  12.9  14.6  12.5  10.4   \n",
       "\n",
       "         FWI  classes  \n",
       "167  fire           1  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['FWI'] == 'fire   ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54743788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will replace this value with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c1b46a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.4\n",
       "dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FWI'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4278b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FWI'] = df['FWI'].replace('fire   ' , '0.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "20d8cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FWI'] = df['FWI'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "980399a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 244 entries, 0 to 245\n",
      "Data columns (total 13 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   day          244 non-null    int32  \n",
      " 1   month        244 non-null    int32  \n",
      " 2   Temperature  244 non-null    int32  \n",
      " 3    RH          244 non-null    int32  \n",
      " 4    Ws          244 non-null    float64\n",
      " 5   Rain         244 non-null    float64\n",
      " 6   FFMC         244 non-null    float64\n",
      " 7   DMC          244 non-null    float64\n",
      " 8   DC           244 non-null    float64\n",
      " 9   ISI          244 non-null    float64\n",
      " 10  BUI          244 non-null    float64\n",
      " 11  FWI          244 non-null    float64\n",
      " 12  classes      244 non-null    int32  \n",
      "dtypes: float64(8), int32(5)\n",
      "memory usage: 21.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b781777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now all the data has been converted into numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a94920f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.232788e-17</td>\n",
       "      <td>0.095772</td>\n",
       "      <td>-0.074209</td>\n",
       "      <td>0.047001</td>\n",
       "      <td>-0.112265</td>\n",
       "      <td>0.224032</td>\n",
       "      <td>0.491571</td>\n",
       "      <td>0.527929</td>\n",
       "      <td>0.177727</td>\n",
       "      <td>0.517229</td>\n",
       "      <td>0.350909</td>\n",
       "      <td>0.201784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>2.232788e-17</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.059017</td>\n",
       "      <td>-0.037884</td>\n",
       "      <td>-0.041447</td>\n",
       "      <td>0.035322</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>0.068178</td>\n",
       "      <td>0.127672</td>\n",
       "      <td>0.061680</td>\n",
       "      <td>0.085822</td>\n",
       "      <td>0.084119</td>\n",
       "      <td>0.022333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>9.577222e-02</td>\n",
       "      <td>-5.901677e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.654443</td>\n",
       "      <td>-0.278132</td>\n",
       "      <td>-0.326786</td>\n",
       "      <td>0.677491</td>\n",
       "      <td>0.483105</td>\n",
       "      <td>0.370498</td>\n",
       "      <td>0.607551</td>\n",
       "      <td>0.455504</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>0.518119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>-7.420934e-02</td>\n",
       "      <td>-3.788419e-02</td>\n",
       "      <td>-0.654443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236084</td>\n",
       "      <td>0.222968</td>\n",
       "      <td>-0.645658</td>\n",
       "      <td>-0.405133</td>\n",
       "      <td>-0.220330</td>\n",
       "      <td>-0.690637</td>\n",
       "      <td>-0.348587</td>\n",
       "      <td>-0.570483</td>\n",
       "      <td>-0.435023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ws</th>\n",
       "      <td>4.700086e-02</td>\n",
       "      <td>-4.144673e-02</td>\n",
       "      <td>-0.278132</td>\n",
       "      <td>0.236084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170169</td>\n",
       "      <td>-0.163255</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>0.076245</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>0.029756</td>\n",
       "      <td>0.029001</td>\n",
       "      <td>-0.066529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain</th>\n",
       "      <td>-1.122654e-01</td>\n",
       "      <td>3.532207e-02</td>\n",
       "      <td>-0.326786</td>\n",
       "      <td>0.222968</td>\n",
       "      <td>0.170169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.544045</td>\n",
       "      <td>-0.288548</td>\n",
       "      <td>-0.296804</td>\n",
       "      <td>-0.347105</td>\n",
       "      <td>-0.299171</td>\n",
       "      <td>-0.322810</td>\n",
       "      <td>-0.379449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFMC</th>\n",
       "      <td>2.240321e-01</td>\n",
       "      <td>1.557668e-02</td>\n",
       "      <td>0.677491</td>\n",
       "      <td>-0.645658</td>\n",
       "      <td>-0.163255</td>\n",
       "      <td>-0.544045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602391</td>\n",
       "      <td>0.503910</td>\n",
       "      <td>0.739730</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.686342</td>\n",
       "      <td>0.770114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMC</th>\n",
       "      <td>4.915710e-01</td>\n",
       "      <td>6.817778e-02</td>\n",
       "      <td>0.483105</td>\n",
       "      <td>-0.405133</td>\n",
       "      <td>-0.001246</td>\n",
       "      <td>-0.288548</td>\n",
       "      <td>0.602391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875358</td>\n",
       "      <td>0.674499</td>\n",
       "      <td>0.982073</td>\n",
       "      <td>0.874924</td>\n",
       "      <td>0.584188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>5.279285e-01</td>\n",
       "      <td>1.276719e-01</td>\n",
       "      <td>0.370498</td>\n",
       "      <td>-0.220330</td>\n",
       "      <td>0.076245</td>\n",
       "      <td>-0.296804</td>\n",
       "      <td>0.503910</td>\n",
       "      <td>0.875358</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.498909</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>0.740178</td>\n",
       "      <td>0.507122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISI</th>\n",
       "      <td>1.777266e-01</td>\n",
       "      <td>6.168011e-02</td>\n",
       "      <td>0.607551</td>\n",
       "      <td>-0.690637</td>\n",
       "      <td>0.015248</td>\n",
       "      <td>-0.347105</td>\n",
       "      <td>0.739730</td>\n",
       "      <td>0.674499</td>\n",
       "      <td>0.498909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.635891</td>\n",
       "      <td>0.908054</td>\n",
       "      <td>0.735511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUI</th>\n",
       "      <td>5.172292e-01</td>\n",
       "      <td>8.582162e-02</td>\n",
       "      <td>0.455504</td>\n",
       "      <td>-0.348587</td>\n",
       "      <td>0.029756</td>\n",
       "      <td>-0.299171</td>\n",
       "      <td>0.589652</td>\n",
       "      <td>0.982073</td>\n",
       "      <td>0.941904</td>\n",
       "      <td>0.635891</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857847</td>\n",
       "      <td>0.583882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FWI</th>\n",
       "      <td>3.509095e-01</td>\n",
       "      <td>8.411895e-02</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>-0.570483</td>\n",
       "      <td>0.029001</td>\n",
       "      <td>-0.322810</td>\n",
       "      <td>0.686342</td>\n",
       "      <td>0.874924</td>\n",
       "      <td>0.740178</td>\n",
       "      <td>0.908054</td>\n",
       "      <td>0.857847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.713695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <td>2.017844e-01</td>\n",
       "      <td>2.233266e-02</td>\n",
       "      <td>0.518119</td>\n",
       "      <td>-0.435023</td>\n",
       "      <td>-0.066529</td>\n",
       "      <td>-0.379449</td>\n",
       "      <td>0.770114</td>\n",
       "      <td>0.584188</td>\n",
       "      <td>0.507122</td>\n",
       "      <td>0.735511</td>\n",
       "      <td>0.583882</td>\n",
       "      <td>0.713695</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      day         month  Temperature        RH        Ws  \\\n",
       "day          1.000000e+00  2.232788e-17     0.095772 -0.074209  0.047001   \n",
       "month        2.232788e-17  1.000000e+00    -0.059017 -0.037884 -0.041447   \n",
       "Temperature  9.577222e-02 -5.901677e-02     1.000000 -0.654443 -0.278132   \n",
       " RH         -7.420934e-02 -3.788419e-02    -0.654443  1.000000  0.236084   \n",
       " Ws          4.700086e-02 -4.144673e-02    -0.278132  0.236084  1.000000   \n",
       "Rain        -1.122654e-01  3.532207e-02    -0.326786  0.222968  0.170169   \n",
       "FFMC         2.240321e-01  1.557668e-02     0.677491 -0.645658 -0.163255   \n",
       "DMC          4.915710e-01  6.817778e-02     0.483105 -0.405133 -0.001246   \n",
       "DC           5.279285e-01  1.276719e-01     0.370498 -0.220330  0.076245   \n",
       "ISI          1.777266e-01  6.168011e-02     0.607551 -0.690637  0.015248   \n",
       "BUI          5.172292e-01  8.582162e-02     0.455504 -0.348587  0.029756   \n",
       "FWI          3.509095e-01  8.411895e-02     0.558800 -0.570483  0.029001   \n",
       "classes      2.017844e-01  2.233266e-02     0.518119 -0.435023 -0.066529   \n",
       "\n",
       "                Rain       FFMC       DMC        DC       ISI       BUI  \\\n",
       "day         -0.112265  0.224032  0.491571  0.527929  0.177727  0.517229   \n",
       "month        0.035322  0.015577  0.068178  0.127672  0.061680  0.085822   \n",
       "Temperature -0.326786  0.677491  0.483105  0.370498  0.607551  0.455504   \n",
       " RH          0.222968 -0.645658 -0.405133 -0.220330 -0.690637 -0.348587   \n",
       " Ws          0.170169 -0.163255 -0.001246  0.076245  0.015248  0.029756   \n",
       "Rain         1.000000 -0.544045 -0.288548 -0.296804 -0.347105 -0.299171   \n",
       "FFMC        -0.544045  1.000000  0.602391  0.503910  0.739730  0.589652   \n",
       "DMC         -0.288548  0.602391  1.000000  0.875358  0.674499  0.982073   \n",
       "DC          -0.296804  0.503910  0.875358  1.000000  0.498909  0.941904   \n",
       "ISI         -0.347105  0.739730  0.674499  0.498909  1.000000  0.635891   \n",
       "BUI         -0.299171  0.589652  0.982073  0.941904  0.635891  1.000000   \n",
       "FWI         -0.322810  0.686342  0.874924  0.740178  0.908054  0.857847   \n",
       "classes     -0.379449  0.770114  0.584188  0.507122  0.735511  0.583882   \n",
       "\n",
       "                  FWI   classes  \n",
       "day          0.350909  0.201784  \n",
       "month        0.084119  0.022333  \n",
       "Temperature  0.558800  0.518119  \n",
       " RH         -0.570483 -0.435023  \n",
       " Ws          0.029001 -0.066529  \n",
       "Rain        -0.322810 -0.379449  \n",
       "FFMC         0.686342  0.770114  \n",
       "DMC          0.874924  0.584188  \n",
       "DC           0.740178  0.507122  \n",
       "ISI          0.908054  0.735511  \n",
       "BUI          0.857847  0.583882  \n",
       "FWI          1.000000  0.713695  \n",
       "classes      0.713695  1.000000  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "92b246a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1f0ca501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  month  Temperature   RH    Ws  Rain   FFMC  DMC    DC  ISI  BUI  FWI\n",
       "0    1      6           29   57  18.0    0.0  65.7  3.4   7.6  1.3  3.4  0.5\n",
       "1    2      6           29   61  13.0    1.3  64.4  4.1   7.6  1.0  3.9  0.4\n",
       "2    3      6           26   82  22.0   13.1  47.1  2.5   7.1  0.3  2.7  0.1\n",
       "3    4      6           25   89  13.0    2.5  28.6  1.3   6.9  0.0  1.7  0.0\n",
       "4    5      6           27   77  16.0    0.0  64.8  3.0  14.2  1.2  3.9  0.5"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8dee232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a4de84bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241    1\n",
       "242    0\n",
       "243    0\n",
       "244    0\n",
       "245    0\n",
       "Name: classes, dtype: int32"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6da44527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5ba9c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "adc2f877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3b93c733",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "8be3835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0c8b74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b37c8e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ad62c5b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9591836734693877"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6ccdc023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  1],\n",
       "       [ 1, 32]], dtype=int64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "381a185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "26ecea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        16\n",
      "           1       0.97      0.97      0.97        33\n",
      "\n",
      "    accuracy                           0.96        49\n",
      "   macro avg       0.95      0.95      0.95        49\n",
      "weighted avg       0.96      0.96      0.96        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7718410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here through logistic regression it self we are getting almost 96 percent accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b1c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fd8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "708e7772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['classes'] == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9f9dbef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['classes'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cae53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above shows this is not an embalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "16340837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050535</td>\n",
       "      <td>0.072036</td>\n",
       "      <td>-0.089374</td>\n",
       "      <td>0.055107</td>\n",
       "      <td>-0.064332</td>\n",
       "      <td>0.204576</td>\n",
       "      <td>0.476476</td>\n",
       "      <td>0.528785</td>\n",
       "      <td>0.153469</td>\n",
       "      <td>0.508455</td>\n",
       "      <td>0.324908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>-0.050535</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062238</td>\n",
       "      <td>-0.002560</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.094092</td>\n",
       "      <td>0.012484</td>\n",
       "      <td>0.048135</td>\n",
       "      <td>0.100725</td>\n",
       "      <td>0.036068</td>\n",
       "      <td>0.061361</td>\n",
       "      <td>0.054476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temperature</th>\n",
       "      <td>0.072036</td>\n",
       "      <td>-0.062238</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.661405</td>\n",
       "      <td>-0.284171</td>\n",
       "      <td>-0.344524</td>\n",
       "      <td>0.676632</td>\n",
       "      <td>0.484405</td>\n",
       "      <td>0.348119</td>\n",
       "      <td>0.592810</td>\n",
       "      <td>0.447717</td>\n",
       "      <td>0.537651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RH</th>\n",
       "      <td>-0.089374</td>\n",
       "      <td>-0.002560</td>\n",
       "      <td>-0.661405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.226050</td>\n",
       "      <td>0.215310</td>\n",
       "      <td>-0.631289</td>\n",
       "      <td>-0.442800</td>\n",
       "      <td>-0.231279</td>\n",
       "      <td>-0.676748</td>\n",
       "      <td>-0.376189</td>\n",
       "      <td>-0.567356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ws</th>\n",
       "      <td>0.055107</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>-0.284171</td>\n",
       "      <td>0.226050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125880</td>\n",
       "      <td>-0.154349</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.080926</td>\n",
       "      <td>0.043780</td>\n",
       "      <td>0.039270</td>\n",
       "      <td>0.050256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rain</th>\n",
       "      <td>-0.064332</td>\n",
       "      <td>0.094092</td>\n",
       "      <td>-0.344524</td>\n",
       "      <td>0.215310</td>\n",
       "      <td>0.125880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.539261</td>\n",
       "      <td>-0.296433</td>\n",
       "      <td>-0.297508</td>\n",
       "      <td>-0.346505</td>\n",
       "      <td>-0.306023</td>\n",
       "      <td>-0.322172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FFMC</th>\n",
       "      <td>0.204576</td>\n",
       "      <td>0.012484</td>\n",
       "      <td>0.676632</td>\n",
       "      <td>-0.631289</td>\n",
       "      <td>-0.154349</td>\n",
       "      <td>-0.539261</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619688</td>\n",
       "      <td>0.505070</td>\n",
       "      <td>0.735169</td>\n",
       "      <td>0.602943</td>\n",
       "      <td>0.682226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMC</th>\n",
       "      <td>0.476476</td>\n",
       "      <td>0.048135</td>\n",
       "      <td>0.484405</td>\n",
       "      <td>-0.442800</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>-0.296433</td>\n",
       "      <td>0.619688</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874316</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.981003</td>\n",
       "      <td>0.882156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DC</th>\n",
       "      <td>0.528785</td>\n",
       "      <td>0.100725</td>\n",
       "      <td>0.348119</td>\n",
       "      <td>-0.231279</td>\n",
       "      <td>0.080926</td>\n",
       "      <td>-0.297508</td>\n",
       "      <td>0.505070</td>\n",
       "      <td>0.874316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.496317</td>\n",
       "      <td>0.940414</td>\n",
       "      <td>0.729232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISI</th>\n",
       "      <td>0.153469</td>\n",
       "      <td>0.036068</td>\n",
       "      <td>0.592810</td>\n",
       "      <td>-0.676748</td>\n",
       "      <td>0.043780</td>\n",
       "      <td>-0.346505</td>\n",
       "      <td>0.735169</td>\n",
       "      <td>0.699431</td>\n",
       "      <td>0.496317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.652847</td>\n",
       "      <td>0.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUI</th>\n",
       "      <td>0.508455</td>\n",
       "      <td>0.061361</td>\n",
       "      <td>0.447717</td>\n",
       "      <td>-0.376189</td>\n",
       "      <td>0.039270</td>\n",
       "      <td>-0.306023</td>\n",
       "      <td>0.602943</td>\n",
       "      <td>0.981003</td>\n",
       "      <td>0.940414</td>\n",
       "      <td>0.652847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FWI</th>\n",
       "      <td>0.324908</td>\n",
       "      <td>0.054476</td>\n",
       "      <td>0.537651</td>\n",
       "      <td>-0.567356</td>\n",
       "      <td>0.050256</td>\n",
       "      <td>-0.322172</td>\n",
       "      <td>0.682226</td>\n",
       "      <td>0.882156</td>\n",
       "      <td>0.729232</td>\n",
       "      <td>0.907200</td>\n",
       "      <td>0.860779</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  day     month  Temperature        RH        Ws     Rain   \\\n",
       "day          1.000000 -0.050535     0.072036 -0.089374  0.055107 -0.064332   \n",
       "month       -0.050535  1.000000    -0.062238 -0.002560  0.003654  0.094092   \n",
       "Temperature  0.072036 -0.062238     1.000000 -0.661405 -0.284171 -0.344524   \n",
       " RH         -0.089374 -0.002560    -0.661405  1.000000  0.226050  0.215310   \n",
       " Ws          0.055107  0.003654    -0.284171  0.226050  1.000000  0.125880   \n",
       "Rain        -0.064332  0.094092    -0.344524  0.215310  0.125880  1.000000   \n",
       "FFMC         0.204576  0.012484     0.676632 -0.631289 -0.154349 -0.539261   \n",
       "DMC          0.476476  0.048135     0.484405 -0.442800  0.009146 -0.296433   \n",
       "DC           0.528785  0.100725     0.348119 -0.231279  0.080926 -0.297508   \n",
       "ISI          0.153469  0.036068     0.592810 -0.676748  0.043780 -0.346505   \n",
       "BUI          0.508455  0.061361     0.447717 -0.376189  0.039270 -0.306023   \n",
       "FWI          0.324908  0.054476     0.537651 -0.567356  0.050256 -0.322172   \n",
       "\n",
       "                 FFMC       DMC        DC       ISI       BUI       FWI  \n",
       "day          0.204576  0.476476  0.528785  0.153469  0.508455  0.324908  \n",
       "month        0.012484  0.048135  0.100725  0.036068  0.061361  0.054476  \n",
       "Temperature  0.676632  0.484405  0.348119  0.592810  0.447717  0.537651  \n",
       " RH         -0.631289 -0.442800 -0.231279 -0.676748 -0.376189 -0.567356  \n",
       " Ws         -0.154349  0.009146  0.080926  0.043780  0.039270  0.050256  \n",
       "Rain        -0.539261 -0.296433 -0.297508 -0.346505 -0.306023 -0.322172  \n",
       "FFMC         1.000000  0.619688  0.505070  0.735169  0.602943  0.682226  \n",
       "DMC          0.619688  1.000000  0.874316  0.699431  0.981003  0.882156  \n",
       "DC           0.505070  0.874316  1.000000  0.496317  0.940414  0.729232  \n",
       "ISI          0.735169  0.699431  0.496317  1.000000  0.652847  0.907200  \n",
       "BUI          0.602943  0.981003  0.940414  0.652847  1.000000  0.860779  \n",
       "FWI          0.682226  0.882156  0.729232  0.907200  0.860779  1.000000  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "26b9d8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Temperature'>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(df['Temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fc81c7a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'month', 'Temperature', ' RH', ' Ws', 'Rain ', 'FFMC', 'DMC',\n",
       "       'DC', 'ISI', 'BUI', 'FWI', 'classes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8e7ae6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='day', ylabel='count'>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df['day'], hue = df['classes'])#don't have much effect on classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6d07a0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Temperature', ylabel='count'>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = df['Temperature'], hue = df['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2061d715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Temperature', ylabel='classes'>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=df['Temperature'], y=df['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "17409777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bed354ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "856b0087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "81267063",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d9eadeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, prediction_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "409c9191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        16\n",
      "           1       1.00      0.91      0.95        33\n",
      "\n",
      "    accuracy                           0.94        49\n",
      "   macro avg       0.92      0.95      0.93        49\n",
      "weighted avg       0.95      0.94      0.94        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will do some parameter tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6692ac71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "b21b27f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start=50, stop=150, num=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "eaff35d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 75, 100, 125, 150]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "de13dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ['gini', 'entropy', 'log_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8f1263f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_depth = [2, 3, 4, 5, 7, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "bd1b6514",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier__min_samples_split=[2,3,5,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e6da4d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = [2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "45a1a441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3fe3417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':n_estimators, 'criterion':criterion, 'min_samples_split':min_samples_split}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6cbf97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=rfc,param_grid = param_grid,cv=5, n_jobs=1, verbose=2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "23c9d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=50; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=125; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=125; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=75; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=75; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=75; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=75; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=125; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=125; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=125; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=125; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=75; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=75; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=75; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=125; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=125; total time=   0.6s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=125; total time=   0.6s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=125; total time=   0.6s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=125; total time=   0.5s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=150; total time=   0.8s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=150; total time=   0.6s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=gini, min_samples_split=6, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=125; total time=   0.5s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=125; total time=   0.7s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=125; total time=   0.7s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=125; total time=   0.6s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=150; total time=   0.6s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=150; total time=   0.7s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=150; total time=   0.8s\n",
      "[CV] END criterion=gini, min_samples_split=7, n_estimators=150; total time=   0.8s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=50; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=50; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=75; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=entropy, min_samples_split=2, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=3, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=150; total time=   0.6s\n",
      "[CV] END criterion=entropy, min_samples_split=4, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=75; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=75; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=75; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=75; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=125; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=125; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=150; total time=   0.5s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=5, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=125; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=6, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=50; total time=   0.1s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=75; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=100; total time=   0.2s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=125; total time=   0.3s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=entropy, min_samples_split=7, n_estimators=150; total time=   0.4s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=2, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=3, n_estimators=150; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=4, n_estimators=150; total time=   0.2s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=75; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=125; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=125; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=125; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=5, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=125; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=125; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=125; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=150; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=6, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=50; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=50; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=75; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=75; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=100; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=125; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=125; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=125; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=125; total time=   0.0s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 387, in fit\n",
      "    trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1041, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 859, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 777, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 222, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 169, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 903, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 348, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=150; total time=   0.1s\n",
      "[CV] END criterion=log_loss, min_samples_split=7, n_estimators=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashm\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.97948718 0.97435897 0.97948718 0.97948718 0.97435897 0.97948718\n",
      " 0.97948718 0.97948718 0.97948718 0.97948718 0.97948718 0.97435897\n",
      " 0.97948718 0.97948718 0.97948718 0.97948718 0.97948718 0.97948718\n",
      " 0.97948718 0.97948718 0.97948718 0.97435897 0.97948718 0.97948718\n",
      " 0.97948718 0.97435897 0.97948718 0.97948718 0.97948718 0.97948718\n",
      " 0.97435897 0.97435897 0.97948718 0.97948718 0.97948718 0.97435897\n",
      " 0.97435897 0.97435897 0.97948718 0.97435897 0.97948718 0.97435897\n",
      " 0.97948718 0.97948718 0.97948718 0.97435897 0.97948718 0.97948718\n",
      " 0.97948718 0.97948718 0.96923077 0.97948718 0.97948718 0.97948718\n",
      " 0.97948718 0.97948718 0.97948718 0.97948718 0.97948718 0.97948718\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7],\n",
       "                         'n_estimators': [50, 75, 100, 125, 150]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6deadd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 50}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cf223cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9794871794871796"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "93e1bcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50, min_samples_split=2, criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "0fc7ebc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5f59dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rfc=rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "894fff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, predict_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "24570ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        16\n",
      "           1       1.00      0.94      0.97        33\n",
      "\n",
      "    accuracy                           0.96        49\n",
      "   macro avg       0.94      0.97      0.95        49\n",
      "weighted avg       0.96      0.96      0.96        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "88618436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0],\n",
       "       [ 2, 31]], dtype=int64)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predict_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af997f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d3a4d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "dd4625e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "12728fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b713afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svc = classifier_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "3e60e978",
   "metadata": {},
   "outputs": [],
   "source": [
    " report = classification_report(y_test, prediction_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "7fad5f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        16\n",
      "           1       0.94      0.94      0.94        33\n",
      "\n",
      "    accuracy                           0.92        49\n",
      "   macro avg       0.91      0.91      0.91        49\n",
      "weighted avg       0.92      0.92      0.92        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dcb49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2ba6aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a61c8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = [2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "8215caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = ['scale', 'auto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "6b05900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid= {'kernel':kernel, 'degree':degree, 'gamma':gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e5793f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=classifier_svc ,param_grid = grid,cv=5, n_jobs=1, verbose=2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "523880df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV] END ...............degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=2, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..............degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=2, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ................degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=2, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=2, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=2, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=2, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=3, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..............degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=3, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ................degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=3, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=3, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=3, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=3, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=scale, kernel=linear; total time=   0.0s\n",
      "[CV] END .................degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END .................degree=4, gamma=scale, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=scale, kernel=rbf; total time=   0.0s\n",
      "[CV] END ..............degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ..............degree=4, gamma=scale, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ................degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ................degree=4, gamma=auto, kernel=linear; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ..................degree=4, gamma=auto, kernel=poly; total time=   0.0s\n",
      "[CV] END ...................degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...................degree=4, gamma=auto, kernel=rbf; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n",
      "[CV] END ...............degree=4, gamma=auto, kernel=sigmoid; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(), n_jobs=1,\n",
       "             param_grid={'degree': [2, 3, 4], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ab0b1491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "af725ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_svc = SVC(degree=2, gamma='auto', kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4da9fe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(degree=2, gamma='auto', kernel='poly')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "ddba1c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_svc = classifier_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "c82a24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_test, prediction_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a66f3a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88        16\n",
      "           1       0.97      0.91      0.94        33\n",
      "\n",
      "    accuracy                           0.92        49\n",
      "   macro avg       0.90      0.92      0.91        49\n",
      "weighted avg       0.92      0.92      0.92        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "57d707d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  1],\n",
       "       [ 3, 30]], dtype=int64)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, prediction_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c5b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hence here the best model is random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5eec3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "64e8f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rfc, open('model2.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6237ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_model = pickle.load(open('model2.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "bf89e3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "25fce788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['day', 'month', 'Temperature', ' RH', ' Ws', 'Rain ', 'FFMC', 'DMC',\n",
       "       'DC', 'ISI', 'BUI', 'FWI'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5020e384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>90</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>27.5</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>90.6</td>\n",
       "      <td>25.8</td>\n",
       "      <td>77.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>22.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>33.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month  Temperature   RH    Ws  Rain   FFMC   DMC     DC  ISI   BUI  \\\n",
       "138   15      6           28   90  15.0    0.0  66.8   7.2   14.7  1.2   7.1   \n",
       "78    18      8           36   54  18.0    0.0  89.4  20.0  110.9  9.7  27.5   \n",
       "233   18      9           36   33  13.0    0.1  90.6  25.8   77.8  9.0  28.2   \n",
       "5      6      6           31   67  14.0    0.0  82.6   5.8   22.2  3.1   7.0   \n",
       "109   18      9           32   49  11.0    0.0  89.4   9.8   33.1  6.8  11.3   \n",
       "\n",
       "      FWI  \n",
       "138   0.6  \n",
       "78   16.1  \n",
       "233  15.4  \n",
       "5     2.5  \n",
       "109   7.7  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8ffd231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"day\":26, \"month\":9, \"Temperature\":30, \" RH\":65, \" Ws\":14, \"Rain \":0.0, \"FFMC\":85.4, \"DMC\":16.0,\n",
    "       \"DC\":44.5, \"ISI\":4.5, \"BUI\":16.9, \"FWI\":6.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a395afcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month  Temperature   RH    Ws  Rain   FFMC   DMC    DC  ISI   BUI  \\\n",
       "241   26      9           30   65  14.0    0.0  85.4  16.0  44.5  4.5  16.9   \n",
       "242   27      9           28   87  15.0    4.4  41.1   6.5   8.0  0.1   6.2   \n",
       "243   28      9           27   87  29.0    0.5  45.9   3.5   7.9  0.4   3.4   \n",
       "244   29      9           24   54  18.0    0.1  79.7   4.3  15.2  1.7   5.1   \n",
       "245   30      9           24   64  15.0    0.2  67.3   3.8  16.5  1.2   4.8   \n",
       "\n",
       "     FWI  classes  \n",
       "241  6.5        1  \n",
       "242  0.0        0  \n",
       "243  0.2        0  \n",
       "244  0.7        0  \n",
       "245  0.5        0  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "793c47f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26, 9, 30, 65, 14, 0.0, 85.4, 16.0, 44.5, 4.5, 16.9, 6.5]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "061f10ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_model.predict([list(dict.values())])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "dcd0581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_test.to_json(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "0ea2f3e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"138\":{\"day\":15,\"month\":6,\"Temperature\":28,\" RH\":90,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":66.8,\"DMC\":7.2,\"DC\":14.7,\"ISI\":1.2,\"BUI\":7.1,\"FWI\":0.6},\"78\":{\"day\":18,\"month\":8,\"Temperature\":36,\" RH\":54,\" Ws\":18.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":20.0,\"DC\":110.9,\"ISI\":9.7,\"BUI\":27.5,\"FWI\":16.1},\"233\":{\"day\":18,\"month\":9,\"Temperature\":36,\" RH\":33,\" Ws\":13.0,\"Rain \":0.1,\"FFMC\":90.6,\"DMC\":25.8,\"DC\":77.8,\"ISI\":9.0,\"BUI\":28.2,\"FWI\":15.4},\"5\":{\"day\":6,\"month\":6,\"Temperature\":31,\" RH\":67,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":82.6,\"DMC\":5.8,\"DC\":22.2,\"ISI\":3.1,\"BUI\":7.0,\"FWI\":2.5},\"109\":{\"day\":18,\"month\":9,\"Temperature\":32,\" RH\":49,\" Ws\":11.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":9.8,\"DC\":33.1,\"ISI\":6.8,\"BUI\":11.3,\"FWI\":7.7},\"150\":{\"day\":27,\"month\":6,\"Temperature\":36,\" RH\":55,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":89.1,\"DMC\":20.9,\"DC\":43.3,\"ISI\":8.0,\"BUI\":20.8,\"FWI\":12.0},\"231\":{\"day\":16,\"month\":9,\"Temperature\":33,\" RH\":26,\" Ws\":13.0,\"Rain \":0.0,\"FFMC\":93.9,\"DMC\":21.2,\"DC\":59.2,\"ISI\":14.2,\"BUI\":22.4,\"FWI\":19.3},\"177\":{\"day\":24,\"month\":7,\"Temperature\":33,\" RH\":63,\" Ws\":17.0,\"Rain \":1.1,\"FFMC\":72.8,\"DMC\":20.9,\"DC\":56.6,\"ISI\":1.6,\"BUI\":21.7,\"FWI\":2.5},\"242\":{\"day\":27,\"month\":9,\"Temperature\":28,\" RH\":87,\" Ws\":15.0,\"Rain \":4.4,\"FFMC\":41.1,\"DMC\":6.5,\"DC\":8.0,\"ISI\":0.1,\"BUI\":6.2,\"FWI\":0.0},\"31\":{\"day\":2,\"month\":7,\"Temperature\":27,\" RH\":75,\" Ws\":19.0,\"Rain \":1.2,\"FFMC\":55.7,\"DMC\":2.4,\"DC\":8.3,\"ISI\":0.8,\"BUI\":2.8,\"FWI\":0.3},\"140\":{\"day\":17,\"month\":6,\"Temperature\":31,\" RH\":69,\" Ws\":17.0,\"Rain \":4.7,\"FFMC\":62.2,\"DMC\":3.9,\"DC\":8.0,\"ISI\":1.1,\"BUI\":3.8,\"FWI\":0.4},\"190\":{\"day\":6,\"month\":8,\"Temperature\":30,\" RH\":54,\" Ws\":14.0,\"Rain \":3.1,\"FFMC\":70.5,\"DMC\":11.0,\"DC\":9.1,\"ISI\":1.3,\"BUI\":10.5,\"FWI\":0.8},\"106\":{\"day\":15,\"month\":9,\"Temperature\":24,\" RH\":82,\" Ws\":15.0,\"Rain \":0.4,\"FFMC\":44.9,\"DMC\":0.9,\"DC\":7.3,\"ISI\":0.2,\"BUI\":1.4,\"FWI\":0.0},\"49\":{\"day\":20,\"month\":7,\"Temperature\":33,\" RH\":65,\" Ws\":15.0,\"Rain \":0.1,\"FFMC\":81.4,\"DMC\":12.3,\"DC\":62.1,\"ISI\":2.8,\"BUI\":16.5,\"FWI\":4.0},\"181\":{\"day\":28,\"month\":7,\"Temperature\":33,\" RH\":57,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":87.5,\"DMC\":15.7,\"DC\":37.6,\"ISI\":6.7,\"BUI\":15.7,\"FWI\":9.0},\"149\":{\"day\":26,\"month\":6,\"Temperature\":36,\" RH\":62,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":87.8,\"DMC\":16.5,\"DC\":34.5,\"ISI\":7.0,\"BUI\":16.4,\"FWI\":9.5},\"195\":{\"day\":11,\"month\":8,\"Temperature\":40,\" RH\":31,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":94.2,\"DMC\":22.5,\"DC\":46.3,\"ISI\":16.6,\"BUI\":22.4,\"FWI\":21.6},\"86\":{\"day\":26,\"month\":8,\"Temperature\":31,\" RH\":78,\" Ws\":18.0,\"Rain \":0.0,\"FFMC\":85.8,\"DMC\":45.6,\"DC\":190.6,\"ISI\":4.7,\"BUI\":57.1,\"FWI\":13.7},\"166\":{\"day\":13,\"month\":7,\"Temperature\":39,\" RH\":45,\" Ws\":13.0,\"Rain \":0.6,\"FFMC\":85.2,\"DMC\":11.3,\"DC\":10.4,\"ISI\":4.2,\"BUI\":10.9,\"FWI\":4.7},\"155\":{\"day\":2,\"month\":7,\"Temperature\":33,\" RH\":48,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":87.6,\"DMC\":7.9,\"DC\":17.8,\"ISI\":6.8,\"BUI\":7.8,\"FWI\":6.4},\"241\":{\"day\":26,\"month\":9,\"Temperature\":30,\" RH\":65,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":85.4,\"DMC\":16.0,\"DC\":44.5,\"ISI\":4.5,\"BUI\":16.9,\"FWI\":6.5},\"161\":{\"day\":8,\"month\":7,\"Temperature\":35,\" RH\":47,\" Ws\":18.0,\"Rain \":6.0,\"FFMC\":80.8,\"DMC\":9.8,\"DC\":9.7,\"ISI\":3.1,\"BUI\":9.4,\"FWI\":3.0},\"173\":{\"day\":20,\"month\":7,\"Temperature\":36,\" RH\":50,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":89.9,\"DMC\":32.7,\"DC\":71.0,\"ISI\":9.5,\"BUI\":32.6,\"FWI\":17.3},\"60\":{\"day\":31,\"month\":7,\"Temperature\":35,\" RH\":64,\" Ws\":17.0,\"Rain \":0.0,\"FFMC\":87.2,\"DMC\":31.9,\"DC\":145.7,\"ISI\":6.8,\"BUI\":41.2,\"FWI\":15.7},\"160\":{\"day\":7,\"month\":7,\"Temperature\":38,\" RH\":43,\" Ws\":13.0,\"Rain \":0.5,\"FFMC\":85.0,\"DMC\":13.0,\"DC\":35.4,\"ISI\":4.1,\"BUI\":13.7,\"FWI\":5.2},\"88\":{\"day\":28,\"month\":8,\"Temperature\":34,\" RH\":64,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":50.2,\"DC\":210.4,\"ISI\":7.3,\"BUI\":62.9,\"FWI\":19.9},\"2\":{\"day\":3,\"month\":6,\"Temperature\":26,\" RH\":82,\" Ws\":22.0,\"Rain \":13.1,\"FFMC\":47.1,\"DMC\":2.5,\"DC\":7.1,\"ISI\":0.3,\"BUI\":2.7,\"FWI\":0.1},\"75\":{\"day\":15,\"month\":8,\"Temperature\":36,\" RH\":55,\" Ws\":13.0,\"Rain \":0.3,\"FFMC\":82.4,\"DMC\":15.6,\"DC\":92.5,\"ISI\":3.7,\"BUI\":22.0,\"FWI\":6.3},\"76\":{\"day\":16,\"month\":8,\"Temperature\":36,\" RH\":61,\" Ws\":18.0,\"Rain \":0.3,\"FFMC\":80.2,\"DMC\":11.7,\"DC\":90.4,\"ISI\":2.8,\"BUI\":17.6,\"FWI\":4.2},\"208\":{\"day\":24,\"month\":8,\"Temperature\":35,\" RH\":38,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":92.1,\"DMC\":51.3,\"DC\":147.7,\"ISI\":12.2,\"BUI\":54.9,\"FWI\":26.9},\"127\":{\"day\":4,\"month\":6,\"Temperature\":30,\" RH\":64,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":79.4,\"DMC\":5.2,\"DC\":15.4,\"ISI\":2.2,\"BUI\":5.6,\"FWI\":1.0},\"41\":{\"day\":12,\"month\":7,\"Temperature\":31,\" RH\":75,\" Ws\":13.0,\"Rain \":0.1,\"FFMC\":75.1,\"DMC\":7.9,\"DC\":27.7,\"ISI\":1.5,\"BUI\":9.2,\"FWI\":0.9},\"240\":{\"day\":25,\"month\":9,\"Temperature\":28,\" RH\":70,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":79.9,\"DMC\":13.8,\"DC\":36.1,\"ISI\":2.4,\"BUI\":14.1,\"FWI\":3.0},\"79\":{\"day\":19,\"month\":8,\"Temperature\":35,\" RH\":62,\" Ws\":19.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":23.2,\"DC\":120.9,\"ISI\":9.7,\"BUI\":31.3,\"FWI\":17.2},\"132\":{\"day\":9,\"month\":6,\"Temperature\":27,\" RH\":59,\" Ws\":18.0,\"Rain \":0.1,\"FFMC\":78.1,\"DMC\":8.5,\"DC\":14.7,\"ISI\":2.4,\"BUI\":8.3,\"FWI\":1.9},\"211\":{\"day\":27,\"month\":8,\"Temperature\":36,\" RH\":54,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":91.0,\"DMC\":65.9,\"DC\":177.3,\"ISI\":10.0,\"BUI\":68.0,\"FWI\":26.1},\"176\":{\"day\":23,\"month\":7,\"Temperature\":31,\" RH\":71,\" Ws\":17.0,\"Rain \":0.0,\"FFMC\":87.3,\"DMC\":46.6,\"DC\":99.0,\"ISI\":6.9,\"BUI\":46.5,\"FWI\":16.3},\"45\":{\"day\":16,\"month\":7,\"Temperature\":28,\" RH\":76,\" Ws\":21.0,\"Rain \":0.0,\"FFMC\":72.6,\"DMC\":7.0,\"DC\":25.5,\"ISI\":0.7,\"BUI\":8.3,\"FWI\":0.4},\"171\":{\"day\":18,\"month\":7,\"Temperature\":33,\" RH\":68,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":86.1,\"DMC\":23.9,\"DC\":51.6,\"ISI\":5.2,\"BUI\":23.9,\"FWI\":9.1},\"236\":{\"day\":21,\"month\":9,\"Temperature\":35,\" RH\":34,\" Ws\":17.0,\"Rain \":0.0,\"FFMC\":92.2,\"DMC\":23.6,\"DC\":97.3,\"ISI\":13.8,\"BUI\":29.4,\"FWI\":21.6},\"157\":{\"day\":4,\"month\":7,\"Temperature\":34,\" RH\":58,\" Ws\":18.0,\"Rain \":0.0,\"FFMC\":88.0,\"DMC\":13.6,\"DC\":36.8,\"ISI\":8.0,\"BUI\":14.1,\"FWI\":9.9},\"182\":{\"day\":29,\"month\":7,\"Temperature\":34,\" RH\":59,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":88.1,\"DMC\":19.5,\"DC\":47.2,\"ISI\":7.4,\"BUI\":19.5,\"FWI\":10.9},\"206\":{\"day\":22,\"month\":8,\"Temperature\":37,\" RH\":53,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":89.5,\"DMC\":41.1,\"DC\":127.5,\"ISI\":8.0,\"BUI\":45.5,\"FWI\":18.1},\"244\":{\"day\":29,\"month\":9,\"Temperature\":24,\" RH\":54,\" Ws\":18.0,\"Rain \":0.1,\"FFMC\":79.7,\"DMC\":4.3,\"DC\":15.2,\"ISI\":1.7,\"BUI\":5.1,\"FWI\":0.7},\"107\":{\"day\":16,\"month\":9,\"Temperature\":30,\" RH\":65,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":78.1,\"DMC\":3.2,\"DC\":15.7,\"ISI\":1.9,\"BUI\":4.2,\"FWI\":0.8},\"133\":{\"day\":10,\"month\":6,\"Temperature\":30,\" RH\":41,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":13.3,\"DC\":22.5,\"ISI\":8.4,\"BUI\":13.1,\"FWI\":10.0},\"22\":{\"day\":23,\"month\":6,\"Temperature\":32,\" RH\":62,\" Ws\":18.0,\"Rain \":0.1,\"FFMC\":81.4,\"DMC\":8.2,\"DC\":47.7,\"ISI\":3.3,\"BUI\":11.5,\"FWI\":3.8},\"183\":{\"day\":30,\"month\":7,\"Temperature\":36,\" RH\":56,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":88.9,\"DMC\":23.8,\"DC\":57.1,\"ISI\":8.2,\"BUI\":23.8,\"FWI\":13.2},\"219\":{\"day\":4,\"month\":9,\"Temperature\":30,\" RH\":66,\" Ws\":15.0,\"Rain \":0.2,\"FFMC\":73.5,\"DMC\":4.1,\"DC\":26.6,\"ISI\":1.5,\"BUI\":6.0,\"FWI\":0.7}}'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "054a2794",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = {\"138\":{\"day\":15,\"month\":6,\"Temperature\":28,\" RH\":90,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":66.8,\"DMC\":7.2,\"DC\":14.7,\"ISI\":1.2,\"BUI\":7.1,\"FWI\":0.6},\"78\":{\"day\":18,\"month\":8,\"Temperature\":36,\" RH\":54,\" Ws\":18.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":20.0,\"DC\":110.9,\"ISI\":9.7,\"BUI\":27.5,\"FWI\":16.1},\"233\":{\"day\":18,\"month\":9,\"Temperature\":36,\" RH\":33,\" Ws\":13.0,\"Rain \":0.1,\"FFMC\":90.6,\"DMC\":25.8,\"DC\":77.8,\"ISI\":9.0,\"BUI\":28.2,\"FWI\":15.4},\"5\":{\"day\":6,\"month\":6,\"Temperature\":31,\" RH\":67,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":82.6,\"DMC\":5.8,\"DC\":22.2,\"ISI\":3.1,\"BUI\":7.0,\"FWI\":2.5},\"109\":{\"day\":18,\"month\":9,\"Temperature\":32,\" RH\":49,\" Ws\":11.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":9.8,\"DC\":33.1,\"ISI\":6.8,\"BUI\":11.3,\"FWI\":7.7},\"150\":{\"day\":27,\"month\":6,\"Temperature\":36,\" RH\":55,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":89.1,\"DMC\":20.9,\"DC\":43.3,\"ISI\":8.0,\"BUI\":20.8,\"FWI\":12.0},\"231\":{\"day\":16,\"month\":9,\"Temperature\":33,\" RH\":26,\" Ws\":13.0,\"Rain \":0.0,\"FFMC\":93.9,\"DMC\":21.2,\"DC\":59.2,\"ISI\":14.2,\"BUI\":22.4,\"FWI\":19.3},\"177\":{\"day\":24,\"month\":7,\"Temperature\":33,\" RH\":63,\" Ws\":17.0,\"Rain \":1.1,\"FFMC\":72.8,\"DMC\":20.9,\"DC\":56.6,\"ISI\":1.6,\"BUI\":21.7,\"FWI\":2.5},\"242\":{\"day\":27,\"month\":9,\"Temperature\":28,\" RH\":87,\" Ws\":15.0,\"Rain \":4.4,\"FFMC\":41.1,\"DMC\":6.5,\"DC\":8.0,\"ISI\":0.1,\"BUI\":6.2,\"FWI\":0.0},\"31\":{\"day\":2,\"month\":7,\"Temperature\":27,\" RH\":75,\" Ws\":19.0,\"Rain \":1.2,\"FFMC\":55.7,\"DMC\":2.4,\"DC\":8.3,\"ISI\":0.8,\"BUI\":2.8,\"FWI\":0.3},\"140\":{\"day\":17,\"month\":6,\"Temperature\":31,\" RH\":69,\" Ws\":17.0,\"Rain \":4.7,\"FFMC\":62.2,\"DMC\":3.9,\"DC\":8.0,\"ISI\":1.1,\"BUI\":3.8,\"FWI\":0.4},\"190\":{\"day\":6,\"month\":8,\"Temperature\":30,\" RH\":54,\" Ws\":14.0,\"Rain \":3.1,\"FFMC\":70.5,\"DMC\":11.0,\"DC\":9.1,\"ISI\":1.3,\"BUI\":10.5,\"FWI\":0.8},\"106\":{\"day\":15,\"month\":9,\"Temperature\":24,\" RH\":82,\" Ws\":15.0,\"Rain \":0.4,\"FFMC\":44.9,\"DMC\":0.9,\"DC\":7.3,\"ISI\":0.2,\"BUI\":1.4,\"FWI\":0.0},\"49\":{\"day\":20,\"month\":7,\"Temperature\":33,\" RH\":65,\" Ws\":15.0,\"Rain \":0.1,\"FFMC\":81.4,\"DMC\":12.3,\"DC\":62.1,\"ISI\":2.8,\"BUI\":16.5,\"FWI\":4.0},\"181\":{\"day\":28,\"month\":7,\"Temperature\":33,\" RH\":57,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":87.5,\"DMC\":15.7,\"DC\":37.6,\"ISI\":6.7,\"BUI\":15.7,\"FWI\":9.0},\"149\":{\"day\":26,\"month\":6,\"Temperature\":36,\" RH\":62,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":87.8,\"DMC\":16.5,\"DC\":34.5,\"ISI\":7.0,\"BUI\":16.4,\"FWI\":9.5},\"195\":{\"day\":11,\"month\":8,\"Temperature\":40,\" RH\":31,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":94.2,\"DMC\":22.5,\"DC\":46.3,\"ISI\":16.6,\"BUI\":22.4,\"FWI\":21.6},\"86\":{\"day\":26,\"month\":8,\"Temperature\":31,\" RH\":78,\" Ws\":18.0,\"Rain \":0.0,\"FFMC\":85.8,\"DMC\":45.6,\"DC\":190.6,\"ISI\":4.7,\"BUI\":57.1,\"FWI\":13.7},\"166\":{\"day\":13,\"month\":7,\"Temperature\":39,\" RH\":45,\" Ws\":13.0,\"Rain \":0.6,\"FFMC\":85.2,\"DMC\":11.3,\"DC\":10.4,\"ISI\":4.2,\"BUI\":10.9,\"FWI\":4.7},\"155\":{\"day\":2,\"month\":7,\"Temperature\":33,\" RH\":48,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":87.6,\"DMC\":7.9,\"DC\":17.8,\"ISI\":6.8,\"BUI\":7.8,\"FWI\":6.4},\"241\":{\"day\":26,\"month\":9,\"Temperature\":30,\" RH\":65,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":85.4,\"DMC\":16.0,\"DC\":44.5,\"ISI\":4.5,\"BUI\":16.9,\"FWI\":6.5},\"161\":{\"day\":8,\"month\":7,\"Temperature\":35,\" RH\":47,\" Ws\":18.0,\"Rain \":6.0,\"FFMC\":80.8,\"DMC\":9.8,\"DC\":9.7,\"ISI\":3.1,\"BUI\":9.4,\"FWI\":3.0},\"173\":{\"day\":20,\"month\":7,\"Temperature\":36,\" RH\":50,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":89.9,\"DMC\":32.7,\"DC\":71.0,\"ISI\":9.5,\"BUI\":32.6,\"FWI\":17.3},\"60\":{\"day\":31,\"month\":7,\"Temperature\":35,\" RH\":64,\" Ws\":17.0,\"Rain \":0.0,\"FFMC\":87.2,\"DMC\":31.9,\"DC\":145.7,\"ISI\":6.8,\"BUI\":41.2,\"FWI\":15.7},\"160\":{\"day\":7,\"month\":7,\"Temperature\":38,\" RH\":43,\" Ws\":13.0,\"Rain \":0.5,\"FFMC\":85.0,\"DMC\":13.0,\"DC\":35.4,\"ISI\":4.1,\"BUI\":13.7,\"FWI\":5.2},\"88\":{\"day\":28,\"month\":8,\"Temperature\":34,\" RH\":64,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":50.2,\"DC\":210.4,\"ISI\":7.3,\"BUI\":62.9,\"FWI\":19.9},\"2\":{\"day\":3,\"month\":6,\"Temperature\":26,\" RH\":82,\" Ws\":22.0,\"Rain \":13.1,\"FFMC\":47.1,\"DMC\":2.5,\"DC\":7.1,\"ISI\":0.3,\"BUI\":2.7,\"FWI\":0.1},\"75\":{\"day\":15,\"month\":8,\"Temperature\":36,\" RH\":55,\" Ws\":13.0,\"Rain \":0.3,\"FFMC\":82.4,\"DMC\":15.6,\"DC\":92.5,\"ISI\":3.7,\"BUI\":22.0,\"FWI\":6.3},\"76\":{\"day\":16,\"month\":8,\"Temperature\":36,\" RH\":61,\" Ws\":18.0,\"Rain \":0.3,\"FFMC\":80.2,\"DMC\":11.7,\"DC\":90.4,\"ISI\":2.8,\"BUI\":17.6,\"FWI\":4.2},\"208\":{\"day\":24,\"month\":8,\"Temperature\":35,\" RH\":38,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":92.1,\"DMC\":51.3,\"DC\":147.7,\"ISI\":12.2,\"BUI\":54.9,\"FWI\":26.9},\"127\":{\"day\":4,\"month\":6,\"Temperature\":30,\" RH\":64,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":79.4,\"DMC\":5.2,\"DC\":15.4,\"ISI\":2.2,\"BUI\":5.6,\"FWI\":1.0},\"41\":{\"day\":12,\"month\":7,\"Temperature\":31,\" RH\":75,\" Ws\":13.0,\"Rain \":0.1,\"FFMC\":75.1,\"DMC\":7.9,\"DC\":27.7,\"ISI\":1.5,\"BUI\":9.2,\"FWI\":0.9},\"240\":{\"day\":25,\"month\":9,\"Temperature\":28,\" RH\":70,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":79.9,\"DMC\":13.8,\"DC\":36.1,\"ISI\":2.4,\"BUI\":14.1,\"FWI\":3.0},\"79\":{\"day\":19,\"month\":8,\"Temperature\":35,\" RH\":62,\" Ws\":19.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":23.2,\"DC\":120.9,\"ISI\":9.7,\"BUI\":31.3,\"FWI\":17.2},\"132\":{\"day\":9,\"month\":6,\"Temperature\":27,\" RH\":59,\" Ws\":18.0,\"Rain \":0.1,\"FFMC\":78.1,\"DMC\":8.5,\"DC\":14.7,\"ISI\":2.4,\"BUI\":8.3,\"FWI\":1.9},\"211\":{\"day\":27,\"month\":8,\"Temperature\":36,\" RH\":54,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":91.0,\"DMC\":65.9,\"DC\":177.3,\"ISI\":10.0,\"BUI\":68.0,\"FWI\":26.1},\"176\":{\"day\":23,\"month\":7,\"Temperature\":31,\" RH\":71,\" Ws\":17.0,\"Rain \":0.0,\"FFMC\":87.3,\"DMC\":46.6,\"DC\":99.0,\"ISI\":6.9,\"BUI\":46.5,\"FWI\":16.3},\"45\":{\"day\":16,\"month\":7,\"Temperature\":28,\" RH\":76,\" Ws\":21.0,\"Rain \":0.0,\"FFMC\":72.6,\"DMC\":7.0,\"DC\":25.5,\"ISI\":0.7,\"BUI\":8.3,\"FWI\":0.4},\"171\":{\"day\":18,\"month\":7,\"Temperature\":33,\" RH\":68,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":86.1,\"DMC\":23.9,\"DC\":51.6,\"ISI\":5.2,\"BUI\":23.9,\"FWI\":9.1},\"236\":{\"day\":21,\"month\":9,\"Temperature\":35,\" RH\":34,\" Ws\":17.0,\"Rain \":0.0,\"FFMC\":92.2,\"DMC\":23.6,\"DC\":97.3,\"ISI\":13.8,\"BUI\":29.4,\"FWI\":21.6},\"157\":{\"day\":4,\"month\":7,\"Temperature\":34,\" RH\":58,\" Ws\":18.0,\"Rain \":0.0,\"FFMC\":88.0,\"DMC\":13.6,\"DC\":36.8,\"ISI\":8.0,\"BUI\":14.1,\"FWI\":9.9},\"182\":{\"day\":29,\"month\":7,\"Temperature\":34,\" RH\":59,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":88.1,\"DMC\":19.5,\"DC\":47.2,\"ISI\":7.4,\"BUI\":19.5,\"FWI\":10.9},\"206\":{\"day\":22,\"month\":8,\"Temperature\":37,\" RH\":53,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":89.5,\"DMC\":41.1,\"DC\":127.5,\"ISI\":8.0,\"BUI\":45.5,\"FWI\":18.1},\"244\":{\"day\":29,\"month\":9,\"Temperature\":24,\" RH\":54,\" Ws\":18.0,\"Rain \":0.1,\"FFMC\":79.7,\"DMC\":4.3,\"DC\":15.2,\"ISI\":1.7,\"BUI\":5.1,\"FWI\":0.7},\"107\":{\"day\":16,\"month\":9,\"Temperature\":30,\" RH\":65,\" Ws\":14.0,\"Rain \":0.0,\"FFMC\":78.1,\"DMC\":3.2,\"DC\":15.7,\"ISI\":1.9,\"BUI\":4.2,\"FWI\":0.8},\"133\":{\"day\":10,\"month\":6,\"Temperature\":30,\" RH\":41,\" Ws\":15.0,\"Rain \":0.0,\"FFMC\":89.4,\"DMC\":13.3,\"DC\":22.5,\"ISI\":8.4,\"BUI\":13.1,\"FWI\":10.0},\"22\":{\"day\":23,\"month\":6,\"Temperature\":32,\" RH\":62,\" Ws\":18.0,\"Rain \":0.1,\"FFMC\":81.4,\"DMC\":8.2,\"DC\":47.7,\"ISI\":3.3,\"BUI\":11.5,\"FWI\":3.8},\"183\":{\"day\":30,\"month\":7,\"Temperature\":36,\" RH\":56,\" Ws\":16.0,\"Rain \":0.0,\"FFMC\":88.9,\"DMC\":23.8,\"DC\":57.1,\"ISI\":8.2,\"BUI\":23.8,\"FWI\":13.2},\"219\":{\"day\":4,\"month\":9,\"Temperature\":30,\" RH\":66,\" Ws\":15.0,\"Rain \":0.2,\"FFMC\":73.5,\"DMC\":4.1,\"DC\":26.6,\"ISI\":1.5,\"BUI\":6.0,\"FWI\":0.7}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "7a054208",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame.from_dict(data1, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "11bba699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>FWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>90</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>27.5</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>90.6</td>\n",
       "      <td>25.8</td>\n",
       "      <td>77.8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.2</td>\n",
       "      <td>15.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>22.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>49</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>33.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month  Temperature   RH    Ws  Rain   FFMC   DMC     DC  ISI   BUI  \\\n",
       "138   15      6           28   90  15.0    0.0  66.8   7.2   14.7  1.2   7.1   \n",
       "78    18      8           36   54  18.0    0.0  89.4  20.0  110.9  9.7  27.5   \n",
       "233   18      9           36   33  13.0    0.1  90.6  25.8   77.8  9.0  28.2   \n",
       "5      6      6           31   67  14.0    0.0  82.6   5.8   22.2  3.1   7.0   \n",
       "109   18      9           32   49  11.0    0.0  89.4   9.8   33.1  6.8  11.3   \n",
       "\n",
       "      FWI  \n",
       "138   0.6  \n",
       "78   16.1  \n",
       "233  15.4  \n",
       "5     2.5  \n",
       "109   7.7  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e36ab0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle_model.predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e7adfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
